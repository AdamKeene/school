
from tensorflow.keras.datasets import mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
-images are numpy arrays, labes are array 0-9

train_images.shape
len(train_labels)
train_labels
test_images.shape
len(test_labels)
test_labels
-layers are like filters extracting representations of data (data distillation)

The network architecture

from tensorflow import keras
from tensorflow.keras import layers
model = keras.Sequential([
    layers.Dense(512, activation="relu"),
    layers.Dense(10, activation="softmax")
])
-adds two dense layers(fully connected), second is a 10-way softmax layer 10 scores each is probability of belonging to a digit

The compilation step

model.compile(optimizer="rmsprop",
              loss="sparse_categorical_crossentropy",
              metrics=["accuracy"])
-need 3 things for compilation: loss function: measure performance on training data and steer in right direction, 
optimizer: mechanism to update itself based on data and loss function, and metrics to monitor: only care about accuracy for this example

Preparing the image data

train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype("float32") / 255
test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype("float32") / 255
-need to reshape into network's shape and scale, from uint8 to float32

"Fitting" the model

model.fit(train_images, train_labels, epochs=5, batch_size=128)
-start training the network, fit method fits model to training data
Using the model to make predictions

test_digits = test_images[0:10]
predictions = model.predict(test_digits)
predictions[0]
predictions[0].argmax()
predictions[0][7]
test_labels[0]
Evaluating the model on new data

test_loss, test_acc = model.evaluate(test_images, test_labels)
print(f"test_acc: {test_acc}")
-diff between training and test data is overfitting



~~BACKPROPOGATION~~
-backpropogation is supervised methos for multilayer feed-forward networks
-feed-forward is uni-directional flow of information forward through hidden nodes to output nodes with no cycles or loops, in contrast with recurrent neural networks that do. feedforward networks are trained using backpropogation.
-backpropogation models a given function by modifying internal weightings to produce an expected output signal. supervised learning method where error between system output and expected output is used to modify internal state.
-requires network structure to be defined of one or more layers where one layer is fully connected to the next, standard is one input one hidden one output. can be for classification or regression, this one is classification. best results in classification problems are when the network has one neuron in the output layer for each class value (one hot encoding)
Initialize Network:

def initialize_network(n_inputs, n_hidden, n_outputs):
	network = list()
	hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]
	network.append(hidden_layer)
	output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]
	network.append(output_layer)
	return network
-each neuron has one weight per input connection plus one for bias
-input layer is just a row from training dataset, first real layer is hidden layer. layers organized here as arrays of dictionaries and network is array of layers.
-good practice to Initialize weights to small random numbers, 0-1 here.

seed(1)
network = initialize_network(2, 1, 2)
for layer in network:
	print(layer)
[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}] -1 neuron 2 input weights + bias
[{'weights': [0.2550690257394217, 0.49543508709194095]}, {'weights': [0.4494910647887381, 0.651592972722763]}] -2 neurons with 1 weight + bias
-2 input weights means 2 input connections
Forward propagate
-output is calculated by propogating input signals through each layer until the output layer outputs its values
-neuron activation, neuron transfer, forward propagation
-input can be a row from training dataset like in hidden layer or outputs from each neuron in the hidden layer like in output layer
activation = sum(weight_i * input_i) + bias

~~MOVIE REVIEWS~~
-binary classification is most common application, in this case positive or negative
from tensorflow.keras.datasets import imdb
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(
    num_words=10000)
-num words means only top 10000 most frequently occurring words in the training data to keep vector data manageable
-labels are 0 or 1 bc binary
train_data[0]
train_labels[0]
max([max(sequence) for sequence in train_data])
-because num_words is set

Decoding reviews back to text

word_index = imdb.get_word_index() -word_index() which is dict mapping words to integer index
reverse_word_index = dict(
    [(value, key) for (key, value) in word_index.items()]) -reverse dict
decoded_review = " ".join(
    [reverse_word_index.get(i - 3, "?") for i in train_data[0]]) -offset by 3 because 0-2 are reserved for padding start of sequence and unknown

Preparing the data
-need to turn lists into tensors, can pad lists and turn them into integer tensors and make first layer capable of handling integer tensors (embedding layer),
or one-hot encode to turn them into vectors of 0s and 1s, and make the first layer a dense layer which handles floating-point vector data

Encoding the integer sequences via multi-hot encoding

import numpy as np
def vectorize_sequences(sequences, dimension=10000):
    results = np.zeros((len(sequences), dimension)) -all zeros matrix of shape len sequences, dimension(shape, kinda like size of data)
    for i, sequence in enumerate(sequences):
        for j in sequence:
            results[i, j] = 1. -sets specific indeces to 1
    return results
x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)

x_train[0]
y_train = np.asarray(train_labels).astype("float32") -vectorize labels
y_test = np.asarray(test_labels).astype("float32")

Building your network
-best type of network when input data is vectors and labels are scalars like this is a simple stack of dense(fully connected) layers with relu activations
-in dense(16, activation='relu') 16 is num hidden units of the layer, hidden unit is a dimension in the representation space of a layer. relu is rectified linear unit, activation function that outputs input if it's positive else zero. sigmoid activation squashes values into [0,1] as a probability for last layer
-dimensionality is how much freedom you're allowing the network to have when learning internal representations, more hidden units allows more complex representations but is more computationally expensive and can cause problems like patterns that aren't real
-two decisions for dense layers: how many layers and how many hidden units. This case 2 intermediate layers 16 units each, third layer with scalar prediction regarding sentiment of current review

Model definition

from tensorflow import keras
from tensorflow.keras import layers

-activation functions adds non linearity, linear hypothesis space is too restricting regardless of how many layers
-for loss function binary_crossentropy is best for binary classification with a probability outputs, crossentropy for probability outputs bc measures distance between probability distributions/ground-truth distribution and predictions
-rmsprop optimizer

model = keras.Sequential([
    layers.Dense(16, activation="relu"),
    layers.Dense(16, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])
Compiling the model

-passing optimizer loss function and metrics as strings bc part of keras, can also configure optimizer parameters to pass custom loss/metric functions instead

model.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])

Validating your approach
-to monitor during training create a validation set with 10k samples from original training data (x_val y_val)

Setting aside a validation set

x_val = x_train[:10000]
partial_x_train = x_train[10000:]
y_val = y_train[:10000]
partial_y_train = y_train[10000:]

Training your model
-20 epochs is 20 iterations over all samples in x_train and y_train tensors, in batches of 512 samples, while monitoring loss and accuracy on 10k samples in validation_data

history = model.fit(partial_x_train,
                    partial_y_train,
                    epochs=20,
                    batch_size=512,
                    validation_data=(x_val, y_val))

-model.fit returns a history object with information about training, 4 entries one per metric being monitored, matplotlib diagram below of training and training and validation loss and training and validation accuracy. training loss/accuracy gets better each epoch but validation accuracy peaks early, overfitting and learning representations specific to training data, overfitting mitigation techniques later

history_dict = history.history
history_dict.keys()
Plotting the training and validation loss

import matplotlib.pyplot as plt
history_dict = history.history
loss_values = history_dict["loss"]
val_loss_values = history_dict["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "bo", label="Training loss")
plt.plot(epochs, val_loss_values, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()
Plotting the training and validation accuracy

plt.clf()
acc = history_dict["accuracy"]
val_acc = history_dict["val_accuracy"]
plt.plot(epochs, acc, "bo", label="Training acc")
plt.plot(epochs, val_acc, "b", label="Validation acc")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()
Retraining a model from scratch

model = keras.Sequential([
    layers.Dense(16, activation="relu"),
    layers.Dense(16, activation="relu"),
    layers.Dense(1, activation="sigmoid")
])
model.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])
model.fit(x_train, y_train, epochs=4, batch_size=512)
results = model.evaluate(x_test, y_test)
results
Using a trained model to generate predictions on new data
model.predict(x_test)